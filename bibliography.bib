@article{Redmon2018,
abstract = {We present some updates to YOLO! We made a bunch of little design changes to make it better. We also trained this new network that's pretty swell. It's a little bigger than last time but more accurate. It's still fast though, don't worry. At 320x320 YOLOv3 runs in 22 ms at 28.2 mAP, as accurate as SSD but three times faster. When we look at the old .5 IOU mAP detection metric YOLOv3 is quite good. It achieves 57.9 mAP@50 in 51 ms on a Titan X, compared to 57.5 mAP@50 in 198 ms by RetinaNet, similar performance but 3.8x faster. As always, all the code is online at https://pjreddie.com/yolo/},
archivePrefix = {arXiv},
arxivId = {1804.02767},
author = {Redmon, Joseph and Farhadi, Ali},
eprint = {1804.02767},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Unknown/2018{\_}YOLOv3 An Incremental Improvement.pdf:pdf},
title = {{YOLOv3: An Incremental Improvement}},
url = {http://arxiv.org/abs/1804.02767},
year = {2018}
}
@article{Litjens2017,
abstract = {Deep learning algorithms, in particular convolutional networks, have rapidly become a methodology of choice for analyzing medical images. This paper reviews the major deep learning concepts pertinent to medical image analysis and summarizes over 300 contributions to the field, most of which appeared in the last year. We survey the use of deep learning for image classification, object detection, segmentation, registration, and other tasks. Concise overviews are provided of studies per application area: neuro, retinal, pulmonary, digital pathology, breast, cardiac, abdominal, musculoskeletal. We end with a summary of the current state-of-the-art, a critical discussion of open challenges and directions for future research.},
archivePrefix = {arXiv},
arxivId = {1702.05747},
author = {Litjens, Geert and Kooi, Thijs and Bejnordi, Babak Ehteshami and Setio, Arnaud Arindra Adiyoso and Ciompi, Francesco and Ghafoorian, Mohsen and van der Laak, Jeroen A.W.M. and van Ginneken, Bram and S{\'{a}}nchez, Clara I.},
doi = {10.1016/j.media.2017.07.005},
eprint = {1702.05747},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Medical Image Analysis/2017{\_}A survey on deep learning in medical image analysis.pdf:pdf},
isbn = {978-1-5386-3220-8},
issn = {13618423},
journal = {Medical Image Analysis},
keywords = {Convolutional neural networks,Deep learning,Medical imaging,Survey},
number = {December 2012},
pages = {60--88},
pmid = {28778026},
publisher = {Elsevier B.V.},
title = {{A survey on deep learning in medical image analysis}},
volume = {42},
year = {2017}
}
@article{Canziani2016,
abstract = {Since the emergence of Deep Neural Networks (DNNs) as a prominent technique in the field of computer vision, the ImageNet classification challenge has played a major role in advancing the state-of-the-art. While accuracy figures have steadily increased, the resource utilisation of winning models has not been properly taken into account. In this work, we present a comprehensive analysis of important metrics in practical applications: accuracy, memory footprint, parameters, operations count, inference time and power consumption. Key findings are: (1) power consumption is independent of batch size and architecture; (2) accuracy and inference time are in a hyperbolic relationship; (3) energy constraint is an upper bound on the maximum achievable accuracy and model complexity; (4) the number of operations is a reliable estimate of the inference time. We believe our analysis provides a compelling set of information that helps design and engineer efficient DNNs.},
archivePrefix = {arXiv},
arxivId = {1605.07678},
author = {Canziani, Alfredo and Paszke, Adam and Culurciello, Eugenio},
eprint = {1605.07678},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Unknown/2016{\_}An Analysis of Deep Neural Network Models for Practical Applications.pdf:pdf},
pages = {1--7},
title = {{An Analysis of Deep Neural Network Models for Practical Applications}},
url = {http://arxiv.org/abs/1605.07678},
year = {2016}
}

@article{Haralick1973,
abstract = {Texture is one of the important characteristics used in identifying objects or regions of interest in an image, whether the image be a photomicrograph, an aerial photograph, or a satellite image. This paper describes some easily computable texture features based on gray-tone spatial dependancies, and illustrates their application in category-identification tasks of three different kinds of image data: photomicrographs of five kinds of sandstones, 1:20 000 panchromatic aerial photographs of eight land-use categories, and Earth Resources Technology Satellite (ERTS) multispecial imagery containing seven land-use categories. We use two kinds of decision rules: one for which the decision regions are convex polyhedra (a piecewise linear decision rule), and one for which the decision regions are rectangular parallelpipeds (a min-max decision rule). In each experiment the data set was divided into two parts, a training set and a test set. Test set identification accuracy is 89{\%} for the photomicrogaphs, 82{\%} for the aerial photographic imagery and 83{\%} for the satellite imagery. These results indicate that the easily computable textural features probably have a general applicability for a wide variety of image-classification applications.},
author = {Haralick, Robert M. and Dinstein, Its'hak and Shanmugam, K.},
doi = {10.1109/TSMC.1973.4309314},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/IEEE Transactions on Systems, Man and Cybernetics/1973{\_}Textural Features for Image Classification.pdf:pdf},
issn = {0018-9472},
journal = {IEEE Transactions on Systems, Man and Cybernetics},
number = {6},
pages = {610--621},
title = {{Textural Features for Image Classification}},
volume = {SMC-3},
year = {1973}
}
@article{Haroon2017,
abstract = {Biopsy and histologic evaluation have been the gold standard to diagnose skin tumors. Reflectance confocal microcopy (RCM) is a noninvasive, innovative diagnostic technique that enables visualization of different skin layers at an almost histologic resolution. RCM has been proven beneficial in management of various cutaneous lesions. This article highlights the clinical significance and future of RCM to diagnose common skin cancers. However, RCM cannot replace currently standard histopathologic diagnosis. More studies are required to better compare the sensitivity and specificity of skin cancer diagnosis using RCM.},
author = {Haroon, Attiya and Shafi, Shahram and Rao, Babar K.},
doi = {10.1016/j.det.2017.06.007},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Dermatologic Clinics/2017{\_}Using Reflectance Confocal Microscopy in Skin Cancer Diagnosis.pdf:pdf},
isbn = {9780323546621},
issn = {15580520},
journal = {Dermatologic Clinics},
keywords = {Melanocytic skin cancer,Nonmelanocytic skin cancer,Reflectance confocal microscopy},
number = {4},
pages = {457--464},
pmid = {28886802},
title = {{Using Reflectance Confocal Microscopy in Skin Cancer Diagnosis}},
volume = {35},
year = {2017}
}
@misc{Jones2001,
annote = {[Online; accessed ]},
author = {Jones, Eric and Oliphant, Travis and Peterson, Pearu and Others},
title = {{{\{}SciPy{\}}: Open source scientific tools for {\{}Python{\}}}},
url = {http://www.scipy.org/}
}
@inproceedings{Cendre2019,
author = {Cendre, Romain and Mansouri, Alamin and Perrot, Jean-luc and Cinotti, Elisa and Marzani, Franck},
booktitle = {GRETSI},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/GRETSI/2019{\_}Extraction et {\'{e}}valuation de caract{\'{e}}ristiques adapt{\'{e}}es pour la classification du Lentigo {\`{a}} partir d ' images de Microscopie Confocal.pdf:pdf},
pages = {2--5},
title = {{Extraction et {\'{e}}valuation de caract{\'{e}}ristiques adapt{\'{e}}es pour la classification du Lentigo {\`{a}} partir d ' images de Microscopie Confocale}},
year = {2019}
}
@article{Hames2016,
abstract = {{\textcopyright} 2015 SPIE. Reflectance confocal microscopy is an emerging tool for imaging human skin, but currently requires expert human assessment. To overcome the need for human experts it is necessary to develop automated tools for automatically assessing reflectance confocal microscopy imagery. This work presents a novel approach to this task, using a bag of visual words approach to represent and classify en-face optical sections from four distinct strata of the skin. A dictionary of representative features is learned from whitened and normalised patches using hierarchical spherical k-means. Each image is then represented by extracting a dense array of patches and encoding each with the most similar element in the dictionary. Linear discriminant analysis is used as a simple linear classifier. The proposed framework was tested on 308 depth stacks from 54 volunteers. Parameters are tuned using 10 fold cross validation on a training sub-set of the data, and final evaluation was performed on a held out test set. The proposed method generated physically plausible profiles of the distinct strata of human skin, and correctly classified 81.4{\%} of sections in the test set.},
author = {Hames, Samuel C. and Ardig{\`{o}}, Marco and Soyer, H. Peter and Bradley, Andrew P. and Prow, Tarl W.},
doi = {10.1371/journal.pone.0153208},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/PLoS ONE/2016{\_}Automated segmentation of skin strata in Reflectance confocal microscopy depth stacks.PDF:PDF},
issn = {19326203},
journal = {PLoS ONE},
number = {4},
pages = {1--12},
title = {{Automated segmentation of skin strata in Reflectance confocal microscopy depth stacks}},
volume = {11},
year = {2016}
}
@article{Guitera2012a,
abstract = {We describe two algorithms to diagnose basal cell carcinomas (BCCs) and melanomas (MMs) using in vivo reflectance confocal microscopy (RCM). A total of 710 consecutive cutaneous lesions excised to exclude malignancy (216 MMs, 266 nevi, 119 BCCs, 67 pigmented facial macules, and 42 other skin tumors) were imaged by RCM. RCM features were correlated with pathology diagnosis to develop diagnostic algorithms. The diagnostic accuracy of the BCC algorithm defined on multivariate analysis of the training set (50{\%}) and tested on the remaining cases was 100{\%} sensitivity, 88.5{\%} specificity. Positive features were polarized elongated features, telangiectasia and convoluted vessels, basaloid nodules, and epidermal shadowing corresponding to horizontal clefting. Negative features were non-visible papillae, disarrangement of the epidermal layer, and cerebriform nests. Multivariate discriminant analysis on the training set (excluding the BCCs) identified seven independently significant features for MM diagnosis. The diagnostic accuracy of the MM algorithm on the test set was 87.6{\%} sensitivity, 70.8{\%} specificity. The four invasive MMs that were misdiagnosed by RCM were all of nevoid subtype. RCM is a highly accurate non-invasive technique for BCC diagnosis. Good diagnostic accuracy was achieved also for MM diagnosis, although rare variants of melanocytic tumors may limit the strict application of the algorithm.},
author = {Guitera, Pascale and Menzies, Scott W. and Longo, Caterina and Cesinaro, Anna M. and Scolyer, Richard A. and Pellacani, Giovanni},
doi = {10.1038/jid.2012.172},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Journal of Investigative Dermatology/2012{\_}In vivo confocal microscopy for diagnosis of melanoma and basal cell carcinoma using a two-step method Analysis of 710 consecutive.pdf:pdf},
issn = {15231747},
journal = {Journal of Investigative Dermatology},
number = {10},
pages = {2386--2394},
publisher = {Nature Publishing Group},
title = {{In vivo confocal microscopy for diagnosis of melanoma and basal cell carcinoma using a two-step method: Analysis of 710 consecutive clinically equivocal cases}},
url = {http://dx.doi.org/10.1038/jid.2012.172},
volume = {132},
year = {2012}
}
@article{Guitera2009,
abstract = {We recently described an in vivo reflectance confocal microscopy (RCM) method and our aim was to evaluate a possible additive value of this type of analysis in the management of melanocytic lesions. In two referral centers (Sydney and Modena), lesions (203 nevi and 123 melanomas (MMs) with a median Breslow thickness of 0.54 mm) were excised on the basis of clinical suspicion (history, dermoscopy examination, and/or digital monitoring). The RCM method was also trialed on a non-biopsied population of 100 lesions, which were clinically and dermoscopically diagnosed as benign nevi. All RCM and dermoscopy diagnoses were performed blinded to the histopathological diagnosis. Firstly, in the study population, a high interobserver agreement (on a subset of 90 lesions) was seen with the RCM method, which had superior specificity (68{\%}, 95{\%} confidence interval (95{\%} CI): 61.1-74.3) for the diagnosis of MM compared with dermoscopy (32{\%}, 95{\%} CI: 25.9-38.7), while showing no difference in sensitivity (91{\%}, 95{\%} CI: 84.6-95.5, RCM; 88{\%}, 95{\%} CI: 80.7-92.6 dermoscopy). The two techniques had a weak correlation, resulting in only 2.4{\%} of MMs being misclassified by both techniques. Diagnosis of light-colored lesions is improved by RCM (specificity 84{\%}, 95{\%} CI: 66.3-94.5) compared with dermoscopy (specificity 39{\%}, 95{\%} CI: 23.7-56.2). Secondly, the RCM method classified 100{\%} of the non-biopsied control nevi population as benign.},
author = {Guitera, Pascale and Pellacani, Giovanni and Longo, Caterina and Seidenari, Stefania and Avramidis, Michelle and Menzies, Scott W.},
doi = {10.1038/jid.2008.193},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/The Journal of investigative dermatology/2009{\_}In vivo reflectance confocal microscopy enhances secondary evaluation of melanocytic lesions.pdf:pdf},
isbn = {0022-202X},
issn = {15231747},
journal = {The Journal of investigative dermatology},
number = {1},
pages = {131--138},
pmid = {18633444},
title = {{In vivo reflectance confocal microscopy enhances secondary evaluation of melanocytic lesions.}},
volume = {129},
year = {2009}
}
@article{Wiltgen2003,
abstract = {Objective: The aim of this study was to evaluate the applicability of tissue counter analysis to the interpretation of skin images. Method: Digital images from microscopic views of benign common nevi and malignant melanoma were classified by the use of features extracted from histogram and co-occurrence matrix. Eighty cases were sampled and split into a training set and a test set. The images were dissected in square elements and the different features were calculated for each element. The classification was done by classification and regression trees (CART) analysis. In the CART procedure, the square elements were split into disjunctive nodes, which were characterized by a relevant subset of the features. The classification results were indicated in the original image in order to evaluate the performance of the procedure. Results: For the learning set and the test set there is a significant difference between benign nevi and malignant melanoma without overlap. Discriminant analysis based on the percentage of 'malignant elements' facilitated a correct classification of all cases. Discussion: Since no image segmentation was needed, problems related to this task were avoided. Though wrong classification of individual elements is unavoidable to some degree, tissue counter analysis shows a good discrimination between benign common nevi and malignant melanoma. Conclusion: In conclusion, tissue counter analysis may be a useful method for the interpretation of melanocytic skin tumors. {\textcopyright} 2002 Elsevier Science Ireland Ltd. All rights reserved.},
author = {Wiltgen, Marco and Gerger, A. and Smolle, J.},
doi = {10.1016/S1386-5056(02)00049-7},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/International Journal of Medical Informatics/2003{\_}Tissue counter analysis of benign common nevi and malignant melanoma.pdf:pdf},
issn = {13865056},
journal = {International Journal of Medical Informatics},
keywords = {Benign common nevi,Computer assisted diagnosis,Malignant melanoma,Medical image processing,Tissue counter analysis},
number = {1},
pages = {17--28},
title = {{Tissue counter analysis of benign common nevi and malignant melanoma}},
volume = {69},
year = {2003}
}
@article{Iyatomi2010,
abstract = {In this paper, we present a classification method of dermoscopy images between melanocytic skin lesions (MSLs) and non-melanocytic skin lesions (NoMSLs). The motivation of this research is to develop a pre-processor of an automated melanoma screening system. Since NoMSLs have a wide variety of shapes and their border is often ambiguous, we developed a new tumor area extraction algorithm to account for these difficulties. We confirmed that this algorithm is capable of handling different dermoscopy images not only those of NoMSLs but also MSLs as well. We determined the tumor area from the image using this new algorithm, calculated a total 428 features from each image, and built a linear classifier. We found only two image features, "the skewness of bright region in the tumor along its major axis" and "the difference between the average intensity in the peripheral part of the tumor and that in the normal skin area using the blue channel" were very efficient at classifying NoMSLs and MSLs. The detection accuracy of MSLs by our classifier using only the above mentioned image feature has a sensitivity of 98.0{\%} and a specificity of 86.6{\%} in a set of 107 non-melanocytic and 548 melanocytic dermoscopy images using a cross-validation test.},
author = {Iyatomi, Hitoshi and Norton, Kerri Ann and Celebi, M. Emre and Schaefer, Gerald and Tanaka, Masaru and Ogawa, Koichi},
doi = {10.1109/IEMBS.2010.5626500},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/2010 Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBC'10/2010{\_}Classification of melanocytic skin lesions from non-melanocytic lesions.pdf:pdf},
isbn = {9781424441235},
issn = {1557-170X},
journal = {2010 Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBC'10},
keywords = {Computer-aided diagnosis,Dermoscopy,Melanoma},
pages = {5407--5410},
pmid = {21096271},
title = {{Classification of melanocytic skin lesions from non-melanocytic lesions}},
year = {2010}
}
@article{Freeman2018,
abstract = {We report development of a low-cost smartphone confocal microscope and its first demonstration of in vivo human skin imaging. The smartphone confocal microscope uses a slit aperture and diffraction grating to conduct two-dimensional confocal imaging without using any beam scanning devices. Lateral and axial resolutions of the smartphone confocal microscope were measured as 2 and 5 µm, respectively. In vivo confocal images of human skin revealed characteristic cellular structures, including spinous and basal keratinocytes and papillary dermis. Results suggest that the smartphone confocal microscope has a potential to examine cellular details in vivo and may help disease diagnosis in resource-poor settings, where conducting standard histopathologic analysis is challenging.},
author = {Freeman, Esther E. and Semeere, Aggrey and Osman, Hany and Peterson, Gary and Rajadhyaksha, Milind and Gonz{\'{a}}lez, Salvador and Martin, Jeffery N. and Anderson, R. Rox and Tearney, Guillermo J. and Kang, Dongkyun},
doi = {10.1364/BOE.9.001906},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Biomedical Optics Express/2018{\_}Smartphone confocal microscopy for imaging cellular structures in human skin in vivo.pdf:pdf},
isbn = {2156-7085 (Print) 2156-7085},
issn = {2156-7085},
journal = {Biomedical Optics Express},
number = {4},
pages = {1906--1915},
pmid = {29675328},
title = {{Smartphone confocal microscopy for imaging cellular structures in human skin in vivo}},
url = {https://www.osapublishing.org/abstract.cfm?URI=boe-9-4-1906},
volume = {9},
year = {2018}
}
@article{Simonyan2014,
abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
archivePrefix = {arXiv},
arxivId = {1409.1556},
author = {Simonyan, Karen and Zisserman, Andrew},
eprint = {1409.1556},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Unknown/2014{\_}Very Deep Convolutional Networks for Large-Scale Image Recognition.pdf:pdf},
pages = {1--14},
title = {{Very Deep Convolutional Networks for Large-Scale Image Recognition}},
url = {http://arxiv.org/abs/1409.1556},
year = {2014}
}
@article{Sinz2017,
abstract = {Background Nonpigmented skin cancer is common, and diagnosis with the unaided eye is error prone. Objective To investigate whether dermatoscopy improves the diagnostic accuracy for nonpigmented (amelanotic) cutaneous neoplasms. Methods We collected a sample of 2072 benign and malignant neoplastic lesions and inflammatory conditions and presented close-up images taken with and without dermatoscopy to 95 examiners with different levels of experience. Results The area under the curve was significantly higher with than without dermatoscopy (0.68 vs 0.64, P {\textless}.001). Among 51 possible diagnoses, the correct diagnosis was selected in 33.1{\%} of cases with and 26.4{\%} of cases without dermatoscopy (P {\textless}.001). For experts, the frequencies of correct specific diagnoses of a malignant lesion improved from 40.2{\%} without to 51.3{\%} with dermatoscopy. For all malignant neoplasms combined, the frequencies of appropriate management strategies increased from 78.1{\%} without to 82.5{\%} with dermatoscopy. Limitations The study deviated from a real-life clinical setting and was potentially affected by verification and selection bias. Conclusions Dermatoscopy improves the diagnosis and management of nonpigmented skin cancer and should be used as an adjunct to examination with the unaided eye.},
author = {Sinz, Christoph and Tschandl, Philipp and Rosendahl, Cliff and Akay, Bengu Nisa and Argenziano, Giuseppe and Blum, Andreas and Braun, Ralph P. and Cabo, Horacio and Gourhant, Jean Yves and Kreusch, Juergen and Lallas, Aimilios and Lapins, Jan and Marghoob, Ashfaq A. and Menzies, Scott W. and Paoli, John and Rabinovitz, Harold S. and Rinner, Christoph and Scope, Alon and Soyer, H. Peter and Thomas, Luc and Zalaudek, Iris and Kittler, Harald},
doi = {10.1016/j.jaad.2017.07.022},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Journal of the American Academy of Dermatology/2017{\_}Accuracy of dermatoscopy for the diagnosis of nonpigmented cancers of the skin.pdf:pdf},
isbn = {0190-9622},
issn = {10976787},
journal = {Journal of the American Academy of Dermatology},
keywords = {dermatoscopy,dermoscopy,diagnosis,keratinocytic skin cancer,melanoma,nonpigmented skin cancer},
number = {6},
pages = {1100--1109},
pmid = {28941871},
publisher = {Elsevier Inc},
title = {{Accuracy of dermatoscopy for the diagnosis of nonpigmented cancers of the skin}},
url = {http://dx.doi.org/10.1016/j.jaad.2017.07.022},
volume = {77},
year = {2017}
}
@article{Menegola2016,
abstract = {Deep learning is the current bet for image classification. Its greed for huge amounts of annotated data limits its usage in medical imaging context. In this scenario transfer learning appears as a prominent solution. In this report we aim to clarify how transfer learning schemes may influence classification results. We are particularly focused in the automated melanoma screening problem, a case of medical imaging in which transfer learning is still not widely used. We explored transfer with and without fine-tuning, sequential transfers and usage of pre-trained models in general and specific datasets. Although some issues remain open, our findings may drive future researches.},
archivePrefix = {arXiv},
arxivId = {1609.01228},
author = {Menegola, Afonso and Fornaciali, Michel and Pires, Ramon and Avila, Sandra and Valle, Eduardo},
eprint = {1609.01228},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Unknown/2016{\_}Towards Automated Melanoma Screening Exploring Transfer Learning Schemes.pdf:pdf},
number = {Ic},
pages = {1--4},
title = {{Towards Automated Melanoma Screening: Exploring Transfer Learning Schemes}},
url = {http://arxiv.org/abs/1609.01228},
year = {2016}
}
@article{Smach2008a,
abstract = {Abstract   This paper is about generalized Fourier descriptors, and their application to the research of invariants under group actions. A general methodology is developed, crucially related to Pontryagin's, Tannaka's, Chu's and Tatsuuma's dualities, from abstract harmonic analysis. Application to motion groups provides a general methodology for pattern recognition. This methodology generalizes the classical basic method of Fourier-invariants of contours of objects. In the paper, we use the results of this theory, inside a Support-Vector-Machine context, for 3D objects-recognition. As usual in practice, we classify 3D objects starting from 2D information. However our method is rather general and could be applied directly to 3D data, in other contexts. Our applications and comparisons with other methods are about human-face recognition, but also we provide tests and comparisons based upon standard data-bases such as the COIL data-base. Our methodology looks extremely efficient, and effective computations are rather simple and low cost. The paper is divided in two parts: first, the part relative to applications and computations, in a SVM environment. The second part is devoted to the development of the general theory of generalized Fourier-descriptors, with several new results, about their completeness in particular. These results lead to simple formulas for motion-invariants of images, that are {\^{a}} complete{\^{a}} in a certain sense, and that are used in the first part of the paper. The computation of these invariants requires only standard FFT estimations, and one dimensional integration.},
author = {Smach, Fethi and Lema{\^{i}}tre, Cedric and Gauthier, Jean Paul and Miteran, Johel and Atri, Mohamed},
doi = {10.1007/s10851-007-0036-3},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Journal of Mathematical Imaging and Vision/2008{\_}Generalized fourier descriptors with applications to objects recognition in SVM context.pdf:pdf},
isbn = {1085100700363},
issn = {09249907},
journal = {Journal of Mathematical Imaging and Vision},
keywords = {Fourier descriptors,Harmonic analysis,Invariants theory,Pattern recognition,SVM},
number = {1},
pages = {43--71},
title = {{Generalized fourier descriptors with applications to objects recognition in SVM context}},
volume = {30},
year = {2008}
}
@article{Gareau2010,
abstract = {In-vivo reflectance confocal microscopy (RCM) shows promise for the early detection of superficial spreading melanoma (SSM). RCM of SSM shows pagetoid melanocytes (PMs) in the epidermis and disarray at the dermal-epidermal junction (DEJ), which are automatically quantified with a computer algorithm that locates depth of the most superficial pigmented surface [D(SPS)(x,y)] containing PMs in the epidermis and pigmented basal cells near the DEJ. The algorithm uses 200 noninvasive confocal optical sections that image the superficial 200 $\mu$m of ten skin sites: five unequivocal SSMs and five nevi. The pattern recognition algorithm automatically identifies PMs in all five SSMs and finds none in the nevi. A large mean gradient $\psi$ (roughness) between laterally adjacent points on D(SPS)(x,y) identifies DEJ disruption in SSM $\psi$ = 11.7 ± 3.7 [-] for n = 5 SSMs versus a small $\psi$ = 5.5 ± 1.0 [-] for n = 5 nevi (significance, p = 0.0035). Quantitative endpoint metrics for malignant characteristics make digital RCM data an attractive diagnostic asset for pathologists, augmenting studies thus far, which have relied largely on visual assessment.},
author = {Gareau, Dan and Hennessy, Ricky and Wan, Eric and Pellacani, Giovanni and Jacques, Steven L.},
doi = {10.1117/1.3524301},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Journal of Biomedical Optics/2010{\_}Automated detection of malignant features in confocal microscopy on superficial spreading melanoma versus nevi.pdf:pdf},
isbn = {1560-2281 (Electronic)$\backslash$r1083-3668 (Linking)},
issn = {10833668},
journal = {Journal of Biomedical Optics},
keywords = {computer vision,confocal microscopy,melanin,melanoma,pathology},
number = {6},
pages = {061713},
pmid = {21198161},
title = {{Automated detection of malignant features in confocal microscopy on superficial spreading melanoma versus nevi}},
url = {http://biomedicaloptics.spiedigitallibrary.org/article.aspx?doi=10.1117/1.3524301},
volume = {15},
year = {2010}
}
@article{He2016,
abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57{\%} error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28{\%} relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC {\&} COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
archivePrefix = {arXiv},
arxivId = {1512.03385},
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
doi = {10.1109/CVPR.2016.90},
eprint = {1512.03385},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition/2016{\_}Deep residual learning for image recognition.pdf:pdf},
isbn = {9781467388504},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {770--778},
title = {{Deep residual learning for image recognition}},
volume = {2016-Decem},
year = {2016}
}
@inproceedings{graf2001,
abstract = {This article deals with various aspects of normalization in the context of Support Vector Machines. We consider fist normalization of the vectors in the input space and point out the inherent limitations. A natural extension to the feature space is then represented by the kernel function normalization. A correction of the position of the Optimal Separating Hyperplane is subsequently introduced so as to suit better these normalized kernels. Numerical experiments finally evaluate the different approaches.},
address = {Berlin, Heidelberg},
author = {Graf, Arnulf B A and Borer, Silvio},
booktitle = {Pattern Recognition},
editor = {Radig, Bernd and Florczyk, Stefan},
isbn = {978-3-540-45404-5},
pages = {277--282},
publisher = {Springer Berlin Heidelberg},
title = {{Normalization in Support Vector Machines}},
year = {2001}
}
@inproceedings{Szegedy2015,
abstract = {Convolutional networks are at the core of most state-of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we explore ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21.2{\%} top-1 and 5.6{\%} top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3.5{\%} top-5 error on the validation set (3.6{\%} error on the test set) and 17.3{\%} top-1 error on the validation set.},
archivePrefix = {arXiv},
arxivId = {1512.00567},
author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon and Wojna, Zbigniew},
booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
doi = {10.1109/CVPR.2016.308},
eprint = {1512.00567},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Proceedings of the IEEE conference on computer vision and pattern recognition/2015{\_}Rethinking the Inception Architecture for Computer Vision.pdf:pdf},
isbn = {978-1-4673-8851-1},
issn = {08866236},
pages = {2818--2826},
pmid = {8190083},
title = {{Rethinking the Inception Architecture for Computer Vision}},
url = {http://arxiv.org/abs/1512.00567},
year = {2015}
}
@article{Cinotti2018,
abstract = {{\textcopyright} 2018 European Academy of Dermatology and Venereology Background: Several dermoscopic and in vivo reflectance confocal microscopy (RCM) diagnostic criteria of lentigo maligna (LM)/lentigo maligna melanoma (LMM) have been identified. However, no study compared the diagnostic accuracy of these techniques. Objective: We evaluated the diagnostic accuracy of dermoscopy and RCM for LM/LMM using a holistic assessment of the images. Methods: A total of 223 facial lesions were evaluated by 21 experts. Diagnostic accuracy of the clinical, dermoscopic and RCM examination was compared. Interinvestigator variability and confidence level in the diagnosis were also evaluated. Results: Overall diagnostic accuracy of the two imaging techniques was good (area under the curve of the sROC function: 0.89). RCM was more sensitive (80{\%}, vs. 61{\%}) and less specific (81{\%} vs. 92{\%}) than dermoscopy for LM/LMM. In particular, RCM showed a higher sensitivity for hypomelanotic and recurrent LM/LMM. RCM had a higher interinvestigator agreement and a higher confidence level in the diagnosis than dermoscopy. Conclusion: Reflectance confocal microscopy and dermoscopy are both useful techniques for the diagnosis of facial lesions and in particular LM/LMM. RCM is particularly suitable for the identification of hypomelanotic and recurrent LM/LMM.},
author = {Cinotti, E. and Labeille, B. and Debarbieux, S. and Carrera, C. and Lacarrubba, F. and Witkowski, A. M. and Moscarella, E. and Arzberger, E. and Kittler, H. and Bahadoran, P. and Gonzalez, S. and Guitera, P. and Agozzino, M. and Farnetani, F. and Hofmann-Wellenhof, R. and Ardig{\`{o}}, M. and Rubegni, P. and Tognetti, L. and {\L}udzik, J. and Zalaudek, I. and Argenziano, G. and Longo, C. and Ribero, S. and Malvehy, J. and Pellacani, G. and Cambazard, F. and Perrot, J. L.},
doi = {10.1111/jdv.14791},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Journal of the European Academy of Dermatology and Venereology/2018{\_}Dermoscopy vs. reflectance confocal microscopy for the diagnosis of lentigo maligna.pdf:pdf},
issn = {14683083},
journal = {Journal of the European Academy of Dermatology and Venereology},
number = {8},
pages = {1284--1291},
pmid = {29341263},
title = {{Dermoscopy vs. reflectance confocal microscopy for the diagnosis of lentigo maligna}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/jdv.14791},
volume = {32},
year = {2018}
}
@article{Batta2015,
abstract = {The value of in vivo reflectance confocal microscopy (RCM) as a noninvasive adjunctive tool in dermatology has steadily advanced since its inception. With RCM, dermatologists can view horizontal sections of lesions in a resolution comparable to histology, observe dynamic processes in living skin, and monitor lesion evolution longitudinally. This article will compare RCM to dermoscopy and histology, review the general principles of the microscope, describe the findings seen on confocal images, and discuss the clinical applications of this noninvasive tool. Additionally, we describe a telepathology network dedicated to the transfer of confocal images to remote dermatopathologists for interpretation. Finally, we will discuss the adoption of RCM and the telepathology network in clinical practice.},
author = {Batta, Mari M. and Kessler, Stephen E. and White, Peter F. and Zhu, Weijian and Fox, Christi Alessi},
doi = {10.1016/S0040-6090(02)00980-X},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Cutis/2015{\_}Reflectance confocal microscopy An overview of technology and advances in telepathology.pdf:pdf},
issn = {00114162},
journal = {Cutis},
number = {5},
pages = {E39--E46},
pmid = {26057520},
title = {{Reflectance confocal microscopy: An overview of technology and advances in telepathology}},
volume = {95},
year = {2015}
}
@inproceedings{Somoza2014,
abstract = {Reflectance Confocal Microscopy (RCM) is a noninvasive imaging tool used in clinical dermatology and skin research, allowing real time visualization of skin structural features at different depths at a resolution comparable to that of conventional histology [1]. Currently, RCM is used to generate a rich skin image stack (about 60 to 100 images per scan) which is visually inspected by experts, a process that is tedious, time consuming and exclusively qualitative. Based on the observation that each of the skin images in the stack can be characterized as a texture, we propose a quantitative approach for automatically classifying the images in the RCM stack, as belonging to the different skin layers: stratum corneum, stratum granulosum, stratum spinosum, stratum basale, and the papillary dermis. A reduced set of images in the stack are used to generate a library of representative texture features named textons. This library is employed to characterize all the images in the stack with a corresponding texton histogram. The stack is ultimately separated into 5 different sets of images, each corresponding to different skin layers, exhibiting good correlation with expert grading. The performance of the method is tested against three RCM stacks and we generate promising classification results. The proposed method is especially valuable considering the currently scarce landscape of quantitative solutions for RCM imaging.},
address = {Cham},
author = {Somoza, Eduardo and Cula, Gabriela Oana and Correa, Catherine and Hirsch, Julie B},
booktitle = {Image Analysis and Recognition},
editor = {Campilho, Aur{\'{e}}lio and Kamel, Mohamed},
isbn = {978-3-319-11755-3},
pages = {141--150},
publisher = {Springer International Publishing},
title = {{Automatic Localization of Skin Layers in Reflectance Confocal Microscopy}},
year = {2014}
}
@article{coelho2012mahotas,
abstract = {Mahotas is a computer vision library for Python. It contains traditional image processing functionality such as filtering and morphological operations as well as more modern computer vision functions for feature computation, including interest point detection and local descriptors. The interface is in Python, a dynamic programming language, which is very appropriate for fast development, but the algorithms are implemented in C++ and are tuned for speed. The library is designed to fit in with the scientific software ecosystem in this language and can leverage the existing infrastructure developed in that language. Mahotas is released under a liberal open source license (MIT License) and is available from (http://github.com/luispedro/mahotas) and from the Python Package Index (http://pypi.python.org/pypi/mahotas).},
archivePrefix = {arXiv},
arxivId = {1211.4907},
author = {Coelho, Luis Pedro},
doi = {10.5334/jors.ac},
eprint = {1211.4907},
issn = {2049-9647},
journal = {arXiv preprint arXiv:1211.4907},
pmid = {25365147},
title = {{Mahotas: Open source software for scriptable computer vision}},
url = {https://arxiv.org/pdf/1211.4907.pdf},
year = {2012}
}
@article{Halimi2017a,
abstract = {The matrix-completion problem has attracted a lot of attention, largely as a result of the celebrated Netflix competition. Two popular approaches for solving the problem are nuclear-norm-regularized matrix approximation (Candes and Tao, 2009, Mazumder, Hastie and Tibshirani, 2010), and maximum-margin matrix factorization (Srebro, Rennie and Jaakkola, 2005). These two procedures are in some cases solving equivalent problems, but with quite different algorithms. In this article we bring the two approaches together, leading to an efficient algorithm for large matrix factorization and completion that outperforms both of these. We develop a software package "softImpute" in R for implementing our approaches, and a distributed version for very large matrices using the "Spark" cluster programming environment.},
archivePrefix = {arXiv},
arxivId = {1410.2596},
author = {Halimi, Abdelghafour and Batatia, Hadj and {Le Digabel}, Jimmy and Josse, Gwendal and Tourneret, Jean Yves},
doi = {10.1364/boe.8.005450},
eprint = {1410.2596},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Biomedical Optics Express/2017{\_}Wavelet-based statistical classification of skin images acquired with reflectance confocal microscopy.pdf:pdf},
issn = {2156-7085},
journal = {Biomedical Optics Express},
keywords = {Image processing - Image analysis - Wavelets - Mic},
number = {12},
pages = {5450--5467},
pmid = {29296480},
publisher = {The Optical Society},
title = {{Wavelet-based statistical classification of skin images acquired with reflectance confocal microscopy}},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5745095/pdf/boe-8-12-5450.pdf},
volume = {8},
year = {2017}
}
@article{Geurts2006,
abstract = {This paper proposes a new tree-based ensemble method for supervised classification and regression problems. It essentially consists of randomizing strongly both attribute and cut-point choice while splitting a tree node. In the extreme case, it builds totally randomized trees whose structures are independent of the output values of the learning sample. The strength of the randomization can be tuned to problem specifics by the appropriate choice of a parameter. We evaluate the robustness of the default choice of this parameter, and we also provide insight on how to adjust it in particular situations. Besides accuracy, the main strength of the resulting algorithm is computational efficiency. A bias/variance analysis of the Extra-Trees algorithm is also provided as well as a geometrical and a kernel characterization of the models induced.},
author = {Geurts, Pierre and Ernst, Damien and Wehenkel, Louis},
doi = {10.1007/s10994-006-6226-1},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Machine Learning/2006{\_}Extremely randomized trees.pdf:pdf},
issn = {08856125},
journal = {Machine Learning},
keywords = {Bias/variance tradeoff,Cut-point randomization,Decision and regression trees,Ensemble methods,Kernel-based models,Supervised learning},
number = {1},
pages = {3--42},
title = {{Extremely randomized trees}},
volume = {63},
year = {2006}
}
@inproceedings{Kose2016b,
abstract = {$\backslash$nWe present a machine learning algorithm that can imitate the clinicians qualitative and visual process of analyzing reflectance confocal microscopy (RCM) mosaics at the dermal epidermal junction (DEJ) of skin. We divide the mosaics into localized areas of processing, and capture the textural appearance of each area using dense Speeded Up Robust Feature (SURF). Using these features, we train a support vector machine (SVM) classifier that can distinguish between meshwork, ring, clod, aspecific and background patterns in benign conditions and melanomas. Preliminary results on 20 RCM mosaics labeled by expert readers show classification with 55 − 81{\%} sensitivity and 81 − 89{\%} specificity in distinguishing these patterns.$\backslash$n},
author = {Kose, Kivanc and Alessi-Fox, Christi and Gill, Melissa and Dy, Jennifer G and Brooks, Dana H and Rajadhyaksha, Milind},
doi = {10.1117/12.2212978},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Unknown/2016{\_}A machine learning method for identifying morphological patterns in reflectance confocal microscopy mosaics of melanocytic skin les.pdf:pdf},
isbn = {9781628419245},
issn = {16057422},
keywords = {computer-aided detection and diagnosis,reflectance confocal microscopy,supervised classifica-},
pages = {968908},
title = {{A machine learning method for identifying morphological patterns in reflectance confocal microscopy mosaics of melanocytic skin lesions in-vivo}},
url = {http://dx.doi.org/10.1117/12.2212978},
volume = {9689},
year = {2016}
}
@article{Szegedy2017,
abstract = {Very deep convolutional networks have been central to the largest advances in image recognition performance in recent years. One example is the Inception architecture that has been shown to achieve very good performance at relatively low computational cost. Recently, the introduction of residual connections in conjunction with a more traditional architecture has yielded state-of-the-art performance in the 2015 ILSVRC challenge; its performance was similar to the latest generation Inception-v3 network. This raises the question: Are there any benefits to combining Inception architectures with residual connections? Here we give clear empirical evidence that training with residual connections accelerates the training of Inception networks significantly. There is also some evidence of residual Inception networks outperforming similarly expensive Inception networks without residual connections by a thin margin. We also present several new streamlined architectures for both residual and nonresidual Inception networks. These variations improve the single-frame recognition performance on the ILSVRC 2012 classification task significantly. We further demonstrate how proper activation scaling stabilizes the training of very wide residual Inception networks. With an ensemble of three residual and one Inception-v4 networks, we achieve 3.08{\%} top-5 error on the test set of the ImageNet classification (CLS) challenge.},
archivePrefix = {arXiv},
arxivId = {1602.07261},
author = {Szegedy, Christian and Ioffe, Sergey and Vanhoucke, Vincent and Alemi, Alexander A.},
eprint = {1602.07261},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/31st AAAI Conference on Artificial Intelligence, AAAI 2017/2017{\_}Inception-v4, inception-ResNet and the impact of residual connections on learning.pdf:pdf},
journal = {31st AAAI Conference on Artificial Intelligence, AAAI 2017},
pages = {4278--4284},
title = {{Inception-v4, inception-ResNet and the impact of residual connections on learning}},
year = {2017}
}
@misc{chollet2015keras,
author = {Chollet, Fran{\c{c}}ois and Others},
publisher = {GitHub},
title = {{Keras}},
url = {https://github.com/fchollet/keras},
year = {2015}
}
@article{Hou2016,
abstract = {Convolutional Neural Networks (CNN) are state-of-the-art models for many image classification tasks. However, to recognize cancer subtypes automatically, training a CNN on gigapixel resolution Whole Slide Tissue Images (WSI) is currently computationally impossible. The differentiation of cancer subtypes is based on cellular-level visual features observed on image patch scale. Therefore, we argue that in this situation, training a patch-level classifier on image patches will perform better than or similar to an image-level classifier. The challenge becomes how to intelligently combine patch-level classification results and model the fact that not all patches will be discriminative. We propose to train a decision fusion model to aggregate patch-level predictions given by patch-level CNNs, which to the best of our knowledge has not been shown before. Furthermore, we formulate a novel Expectation-Maximization (EM) based method that automatically locates discriminative patches robustly by utilizing the spatial relationships of patches. We apply our method to the classification of glioma and non-small-cell lung carcinoma cases into subtypes. The classification accuracy of our method is similar to the inter-observer agreement between pathologists. Although it is impossible to train CNNs on WSIs, we experimentally demonstrate using a comparable non-cancer dataset of smaller images that a patch-based CNN can outperform an image-based CNN.},
archivePrefix = {arXiv},
arxivId = {arXiv:1504.07947v5},
author = {Hou, Le and Samaras, Dimitris and Kurc, Tahsin M. and Gao, Yi and Davis, James E. and Saltz, Joel H.},
doi = {10.1109/CVPR.2016.266},
eprint = {arXiv:1504.07947v5},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition/2016{\_}Patch-Based Convolutional Neural Network for Whole Slide Tissue Image Classification.pdf:pdf},
isbn = {9781467388504},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {2424--2433},
title = {{Patch-Based Convolutional Neural Network for Whole Slide Tissue Image Classification}},
volume = {2016-Decem},
year = {2016}
}
@article{Pathan2018,
abstract = {Computerized image analysis methods for dermoscopy are primarily of great interest and benefit, as it provides significant information about the lesion, which can be of pertinence for the clinicians and a stand-alone warning implement. Computer-based diagnostic systems require dedicated image processing algorithms to provide mathematical descriptions of the suspected regions, such systems hold a great potential in oncology. In this paper, we have performed a review of the state of art techniques used in computer-aided diagnostic systems, by giving the domain aspects of melanoma followed by the prominent techniques used in each of the steps. The steps include dermoscopic image pre-processing, segmentation, extraction and selection of peculiar features, and relegation of skin lesions. The paper also presents cognizance to judge the consequentiality of every methodology utilized in the literature, in addition to the corresponding results obtained in this perspective. The inadequacies and the future research directions are accentuated.},
author = {Pathan, Sameena and Prabhu, K. Gopalakrishna and Siddalingaswamy, P. C.},
doi = {10.1016/j.bspc.2017.07.010},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Biomedical Signal Processing and Control/2018{\_}Techniques and algorithms for computer aided diagnosis of pigmented skin lesions—A review.pdf:pdf},
isbn = {1875-0362},
issn = {17468108},
journal = {Biomedical Signal Processing and Control},
keywords = {Acquisition,Classification,Dermoscopy,Melanoma,Pigmented skin lesions (PSLs),Segmentation},
pages = {237--262},
pmid = {618571949},
title = {{Techniques and algorithms for computer aided diagnosis of pigmented skin lesions—A review}},
volume = {39},
year = {2018}
}
@article{Esteva2017,
abstract = {Skin cancer, the most common human malignancy, is primarily diagnosed visually, beginning with an initial clinical screening and followed potentially by dermoscopic analysis, a biopsy and histopathological examination. Automated classification of skin lesions using images is a challenging task owing to the fine-grained variability in the appearance of skin lesions. Deep convolutional neural networks (CNNs) show potential for general and highly variable tasks across many fine-grained object categories. Here we demonstrate classification of skin lesions using a single CNN, trained end-to-end from images directly, using only pixels and disease labels as inputs. We train a CNN using a dataset of 129,450 clinical images-two orders of magnitude larger than previous datasets-consisting of 2,032 different diseases. We test its performance against 21 board-certified dermatologists on biopsy-proven clinical images with two critical binary classification use cases: keratinocyte carcinomas versus benign seborrheic keratoses; and malignant melanomas versus benign nevi. The first case represents the identification of the most common cancers, the second represents the identification of the deadliest skin cancer. The CNN achieves performance on par with all tested experts across both tasks, demonstrating an artificial intelligence capable of classifying skin cancer with a level of competence comparable to dermatologists. Outfitted with deep neural networks, mobile devices can potentially extend the reach of dermatologists outside of the clinic. It is projected that 6.3 billion smartphone subscriptions will exist by the year 2021 (ref. 13) and can therefore potentially provide low-cost universal access to vital diagnostic care.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Esteva, Andre and Kuprel, Brett and Novoa, Roberto A. and Ko, Justin and Swetter, Susan M. and Blau, Helen M. and Thrun, Sebastian},
doi = {10.1038/nature21056},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Nature/2017{\_}Dermatologist-level classification of skin cancer with deep neural networks.pdf:pdf},
isbn = {0028-0836},
issn = {14764687},
journal = {Nature},
number = {7639},
pages = {115--118},
pmid = {28117445},
title = {{Dermatologist-level classification of skin cancer with deep neural networks}},
volume = {542},
year = {2017}
}
@article{Wiltgen2008,
abstract = {OBJECTIVES: Confocal laser scanning microscopy (CLSM) is used for quick medical checkups. The aim of this study is to check the discrimination power of texture features for the automatic identification of diagnostic significant regions in CLSM views of skin lesions. METHODS: In tissue counter analysis (TCA) the images are dissected in equal square elements, where different classes of features are calculated out. Features defined in the spatial domain are based on histogram (grey level distribution) and co-occurrence matrix (grey level combinations). The features defined in the frequency domain are based on spectral properties of the wavelet Daubechie 4 transform (texture exploration at different scales) and the Fourier transform (global texture properties are localized in the spectrum). Hundred cases of benign common nevi and malignant melanoma were used as the study set. Classification was done with CART (Classification and Regression Trees) analysis which splits the set of square elements into homogenous terminal nodes and generates a set of splitting rules. RESULTS: Features based on the wavelet transform provide the best results with 96.0{\%} of correctly classified elements from benign common nevi and 97.0{\%} from malignant melanoma. The classification results are relocated to the images by use of the splitting rules as diagnostic aid. The discriminated square elements are highlighted in the images, showing tissue with features in good accordance with typical diagnostic CLSM features. CONCLUSION: Square elements with more than 80{\%} of discrimination power enable the identification of diagnostic highly significant parts in confocal microscopic views of malignant melanoma.},
author = {Wiltgen, Marco and Gerger, A. and Wagner, C. and Smolle, J.},
doi = {10.3414/ME0463},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Methods of Information in Medicine/2008{\_}Automatic identification of diagnostic significant regions in confocal laser scanning microscopy of melanocytic skin tumors.pdf:pdf},
issn = {00261270},
journal = {Methods of Information in Medicine},
keywords = {Computer-assisted diagnosis,Confocal laser scanning microscopy,Medical image processing,Tissue counter analysis},
number = {1},
pages = {14--25},
pmid = {18213424},
title = {{Automatic identification of diagnostic significant regions in confocal laser scanning microscopy of melanocytic skin tumors}},
volume = {47},
year = {2008}
}
@article{Cawley2010,
abstract = {Model selection strategies for machine learning algorithms typically involve$\backslash$nthe numerical optimisation of an appropriate model selection criterion, often$\backslash$nbased on an estimator of generalisation performance, such as k-fold $\backslash$ncross-validation. The error of such an estimator can be broken down into bias $\backslash$nand variance components. While unbiasedness is often cited as a beneficial $\backslash$nquality of a model selection criterion, we demonstrate that a low variance is $\backslash$nat least as important, as a non-negligible variance introduces the potential $\backslash$nfor over-fitting in model selection as well as in training the model. While $\backslash$nthis observation is in hindsight perhaps rather obvious, the degradation in $\backslash$nperformance due to over-fitting the model selection criterion can be $\backslash$nsurprisingly large, an observation that appears to have received little $\backslash$nattention in the machine learning literature to date. In this paper, we show $\backslash$nthat the effects of this form of over-fitting are often of comparable $\backslash$nmagnitude to differences in performance between learning algorithms, and thus $\backslash$ncannot be ignored in empirical evaluation. Furthermore, we show that some $\backslash$ncommon performance evaluation practices are susceptible to a form of selection $\backslash$nbias as a result of this form of over-fitting and hence are unreliable. We $\backslash$ndiscuss methods to avoid over-fitting in model selection and subsequent $\backslash$nselection bias in performance evaluation, which we hope will be incorporated $\backslash$ninto best practice. While this study concentrates on cross-validation based $\backslash$nmodel selection, the findings are quite general and apply to any model $\backslash$nselection practice involving the optimisation of a model selection criterion $\backslash$nevaluated over a finite sample of data, including maximisation of the Bayesian $\backslash$nevidence and optimisation of performance bounds.},
author = {Cawley, Gavin C. and Talbot, Nicola L.},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Journal of Machine Learning Research/2010{\_}On Over-fitting in Model Selection and Subsequent Selection Bias in Performance Evaluation.pdf:pdf},
issn = {1532-4435},
journal = {Journal of Machine Learning Research},
keywords = {bias-variance trade-off,model selection,over-,performance evaluation,selection bias},
pages = {2079--2107},
title = {{On Over-fitting in Model Selection and Subsequent Selection Bias in Performance Evaluation}},
url = {http://dl.acm.org/citation.cfm?id=1756006.1859921},
volume = {11},
year = {2010}
}
@article{Rastgoo2015,
abstract = {Dysplastic classification.Malignant melanoma causes the majority of deaths related to skin cancer. Nevertheless, it is the most treatable one, depending on its early diagnosis. The early prognosis is a challenging task for both clinicians and dermatologist, due to the characteristic similarities of melanoma with other skin lesions such as dysplastic nevi. In the past decades, several computerized lesion analysis algorithms have been proposed by the research community for detection of melanoma. These algorithms mostly focus on differentiating melanoma from benign lesions and few have considered the case of melanoma against dysplastic nevi. In this paper, we consider the most challenging task and propose an automatic framework for differentiation of melanoma from dysplastic nevi. The proposed framework also considers combination and comparison of several texture features beside the well used colour and shape features based on "ABCD" clinical rule in the literature. Focusing on dermoscopy images, we evaluate the performance of the framework using two feature extraction approaches, global and local (bag of words) and three classifiers such as support vector machine, gradient boosting and random forest. Our evaluation revealed the potential of texture features and random forest as an almost independent classifier. Using texture features and random forest for differentiation of melanoma and dysplastic nevi, the framework achieved the highest sensitivity of 98{\%} and specificity of 70{\%}.},
author = {Rastgoo, Mojdeh and Garcia, Rafael and Morel, Olivier and Marzani, Franck},
doi = {10.1016/j.compmedimag.2015.02.011},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Computerized Medical Imaging and Graphics/2015{\_}Automatic differentiation of melanoma from dysplastic nevi.pdf:pdf},
isbn = {0895-6111},
issn = {18790771},
journal = {Computerized Medical Imaging and Graphics},
keywords = {Classification,Colour,Dermoscopy imaging,Dysplastic,Machine learning,Melanoma,Shape features,Texture},
pages = {44--52},
pmid = {25797605},
title = {{Automatic differentiation of melanoma from dysplastic nevi}},
volume = {43},
year = {2015}
}
@article{pedregosa2011scikit,
abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
author = {Pedregosa, Fabian and Varoquaux, Ga{\"{e}}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Others},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Journal of machine learning research/2011{\_}Scikit-learn Machine Learning in Python.pdf:pdf},
issn = {1532-4435},
journal = {Journal of machine learning research},
number = {Oct},
pages = {2825--2830},
title = {{Scikit-learn: Machine Learning in Python}},
url = {http://dl.acm.org/citation.cfm?id=1953048.2078195},
volume = {12},
year = {2011}
}
@article{Gerger2006,
abstract = {BACKGROUND: Melanoma and nonmelanoma skin cancer are the most frequent malignant tumors by far among whites. Currently, early diagnosis is the most efficient method for preventing a fatal outcome. In vivo confocal laser-scanning microscopy (CLSM) is a recently developed potential diagnostic tool. METHODS: One hundred seventeen melanocytic skin lesions and 45 nonmelanocytic skin lesions (90 benign nevi, 27 malignant melanomas, 15 basal cell carcinomas, and 30 seborrheic keratoses) were sampled consecutively and were examined using proprietary CLSM equipment. Stored images were rated by 4 independent observers. RESULTS: Differentiation between melanoma and all other lesions based solely on CLSM examination was achieved with a positive predictive value of 94.22{\%}. Malignant lesions (melanoma and basal cell carcinoma) as a group were diagnosed with a positive predictive value of 96.34{\%}. Assessment of distinct CLSM features showed a strong interobserver correlation (kappa {\textgreater}0.80 for 11 of 13 criteria). Classification and regression tree analysis yielded a 3-step algorithm based on only 3 criteria, facilitating a correct classification in 96.30{\%} of melanomas, 98.89{\%} of benign nevi, and 100{\%} of basal cell carcinomas and seborrheic keratoses. CONCLUSIONS: In vivo CLSM examination appeared to be a promising method for the noninvasive assessment of melanoma and nonmelanoma skin tumors.},
author = {Gerger, Armin and Koller, Silvia and Weger, Wolfgang and Richtig, Erika and Kerl, Helmut and Samonigg, Hellmut and Krippl, Peter and Smolle, Josef},
doi = {10.1002/cncr.21910},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Cancer/2006{\_}Sensitivity and specificity of confocal laser-scanning microscopy for in vivo diagnosis of malignant skin tumors.pdf:pdf},
isbn = {1097-0142},
issn = {0008543X},
journal = {Cancer},
keywords = {Basal cell carcinoma,Confocal laser-scanning microscopy,Malignant melanoma,Sensitivity,Specificity},
number = {1},
pages = {193--200},
pmid = {16615102},
title = {{Sensitivity and specificity of confocal laser-scanning microscopy for in vivo diagnosis of malignant skin tumors}},
volume = {107},
year = {2006}
}
@inproceedings{Halimi2017b,
author = {Halimi, A and Batatia, H and Digabel, J Le and Josse, G and Tourneret, J Y},
booktitle = {2017 IEEE 7th International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)},
doi = {10.1109/CAMSAP.2017.8313069},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/2017 IEEE 7th International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)/2017{\_}Statistical modeling and classification of reflectance confocal microscopy images.pdf:pdf},
keywords = {Classification algorithms,Convergence,Junctions,Maximum likelihood estimation,Microscopy,Reflectance confocal microscopy,Skin,array signal processing,computational complexity,cost function,direction-of-arrival estimation,estimation performance,lentigo characterization,matrix algebra,maximum likelihood estimation,natural gradient,optimisation,signal processing,tensors,time series},
pages = {1--5},
title = {{Statistical modeling and classification of reflectance confocal microscopy images}},
year = {2017}
}
@inproceedings{Deng2008,
abstract = {The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called {\&}{\#}x201C;ImageNet{\&}{\#}x201D;, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.},
author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
booktitle = {2009 IEEE Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2009.5206848},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/2009 IEEE Conference on Computer Vision and Pattern Recognition/2009{\_}ImageNet A large-scale hierarchical image database.pdf:pdf},
isbn = {978-1-4244-3992-8},
issn = {1063-6919},
number = {19},
pages = {248--255},
pmid = {18332136},
title = {{ImageNet: A large-scale hierarchical image database}},
volume = {283},
year = {2009}
}
@article{Xu2015,
abstract = {{\textcopyright} 2015 IEEE.We propose a simple, efficient and effective method using deep convolutional activation features (CNNs) to achieve stat-of-the-art classification and segmentation for the MICCAI 2014 Brain Tumor Digital Pathology Challenge. Common traits of such medical image challenges are characterized by large image dimensions (up to the gigabyte size of an image), a limited amount of training data, and significant clinical feature representations. To tackle these challenges, we transfer the features extracted from CNNs trained with a very large general image database to the medical image challenge. In this paper, we used CNN activations trained by ImageNet to extract features (4096 neurons, 13.3{\%} active). In addition, feature selection, feature pooling, and data augmentation are used in our work. Our system obtained 97.5{\%} accuracy on classification and 84{\%} accuracy on segmentation, demonstrating a significant performance gain over other participating teams.},
author = {Xu, Yan and Jia, Zhipeng and Ai, Yuqing and Zhang, Fang and Lai, Maode and Chang, Eric I.Chao},
doi = {10.1109/ICASSP.2015.7178109},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings/2015{\_}Deep convolutional activation features for large scale Brain Tumor histopathology image classification and.pdf:pdf},
isbn = {9781467369978},
issn = {15206149},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
keywords = {classification,deep convolutional activation features,deep learning,feature learning,segmentation},
pages = {947--951},
title = {{Deep convolutional activation features for large scale Brain Tumor histopathology image classification and segmentation}},
volume = {2015-Augus},
year = {2015}
}
@misc{Farberg2017a,
author = {Farberg, Aaron S. and Rigel, Darrell S.},
booktitle = {Dermatologic Clinics},
doi = {10.1016/j.det.2017.06.019},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Dermatologic Clinics/2017{\_}The Importance of Early Recognition of Skin Cancer.pdf:pdf},
isbn = {9780323546621},
issn = {15580520},
keywords = {Medicine},
mendeley-tags = {Medicine},
number = {4},
pages = {xv--xvi},
title = {{The Importance of Early Recognition of Skin Cancer}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0733863517300955},
volume = {35},
year = {2017}
}
@article{Kolm2012,
author = {Kolm, Isabel and Braun, Ralph P.},
doi = {10.1007/978-3-642-21997-9_2},
isbn = {9783642219979},
journal = {Reflectance Confocal Microscopy for Skin Diseases},
pages = {7--10},
title = {{How reflectance confocal microscopy works}},
year = {2012}
}
@article{Zoph2018,
abstract = {Developing neural network image classification models often requires significant architecture engineering. In this paper, we study a method to learn the model architectures directly on the dataset of interest. As this approach is expensive when the dataset is large, we propose to search for an architectural building block on a small dataset and then transfer the block to a larger dataset. The key contribution of this work is the design of a new search space (which we call the 'NASNet search space') which enables transferability. In our experiments, we search for the best convolutional layer (or 'cell') on the CIFAR-10 dataset and then apply this cell to the ImageNet dataset by stacking together more copies of this cell, each with their own parameters to design a convolutional architecture, which we name a 'NASNet architecture'. We also introduce a new regularization technique called ScheduledDropPath that significantly improves generalization in the NASNet models. On CIFAR-10 itself, a NASNet found by our method achieves 2.4{\%} error rate, which is state-of-the-art. Although the cell is not searched for directly on ImageNet, a NASNet constructed from the best cell achieves, among the published works, state-of-the-art accuracy of 82.7{\%} top-1 and 96.2{\%} top-5 on ImageNet. Our model is 1.2{\%} better in top-1 accuracy than the best human-invented architectures while having 9 billion fewer FLOPS - a reduction of 28{\%} in computational demand from the previous state-of-the-art model. When evaluated at different levels of computational cost, accuracies of NASNets exceed those of the state-of-the-art human-designed models. For instance, a small version of NASNet also achieves 74{\%} top-1 accuracy, which is 3.1{\%} better than equivalently-sized, state-of-the-art models for mobile platforms. Finally, the image features learned from image classification are generically useful and can be transferred to other computer vision problems. On the task of object detection, the learned features by NASNet used with the Faster-RCNN framework surpass state-of-the-art by 4.0{\%} achieving 43.1{\%} mAP on the COCO dataset.},
archivePrefix = {arXiv},
arxivId = {1707.07012},
author = {Zoph, Barret and Vasudevan, Vijay and Shlens, Jonathon and Le, Quoc V.},
doi = {10.1109/CVPR.2018.00907},
eprint = {1707.07012},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition/2018{\_}Learning Transferable Architectures for Scalable Image Recognition.pdf:pdf},
isbn = {9781538664209},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {8697--8710},
title = {{Learning Transferable Architectures for Scalable Image Recognition}},
year = {2018}
}
@article{Doran2014,
abstract = {The standard support vector machine (SVM) formulation, widely used for supervised learning, possesses several intuitive and desirable properties. In particular, it is convex and assigns zero loss to solutions if, and only if, they correspond to consistent classifying hyperplanes with some nonzero margin. The traditional SVM formulation has been heuristically extended to multiple-instance (MI) classification in various ways. In this work, we analyze several such algorithms and observe that all MI techniques lack at least one of the desirable properties above. Further, we show that this tradeoff is fundamental, stems from the topological properties of consistent classifying hyperplanes for MI data, and is related to the computational complexity of learning MI hyperplanes. We then study the empirical consequences of this three-way tradeoff in MI classification using a large group of algorithms and datasets. We find that the experimental observations generally support our theoretical results, and properties such as the labeling task (instance versus bag labeling) influence the effects of different tradeoffs. {\textcopyright} 2013 The Author(s).},
author = {Doran, Gary and Ray, Soumya},
doi = {10.1007/s10994-013-5429-5},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Machine Learning/2014{\_}A theoretical and empirical analysis of support vector machine methods for multiple-instance classification.pdf:pdf},
issn = {15730565},
journal = {Machine Learning},
keywords = {Kernel methods,Multiple-instance learning,Support vector machines},
number = {1-2},
pages = {79--102},
title = {{A theoretical and empirical analysis of support vector machine methods for multiple-instance classification}},
volume = {97},
year = {2014}
}
@inproceedings{Cendre2019a,
author = {Cendre, Romain and Mansouri, Alamin and Perrot, Jean-luc and Cinotti, Elisa and Benezeth, Yannick and Marzani, Franck},
booktitle = {ICSIP},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/ICSIP/2019{\_}Two schemes for automated diagnosis of Lentigo on Confocal Microscopy images.pdf:pdf},
keywords = {-dermatology,classification,lentigo,reflectance},
title = {{Two schemes for automated diagnosis of Lentigo on Confocal Microscopy images}},
year = {2019}
}
@article{foulds_frank_2010,
author = {Foulds, James and Frank, Eibe},
doi = {10.1017/S026988890999035X},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/The Knowledge Engineering Review/2010{\_}A review of multi-instance learning assumptions.pdf:pdf},
journal = {The Knowledge Engineering Review},
number = {1},
pages = {1--25},
publisher = {Cambridge University Press},
title = {{A review of multi-instance learning assumptions}},
volume = {25},
year = {2010}
}
@article{Lupu2019,
abstract = {Basal cell carcinoma (BCC) is the most common cancer worldwide and its incidence is constantly rising. Early diagnosis and treatment can significantly reduce patient morbidity and healthcare costs. The value of reflectance confocal microscopy (RCM) in non-melanoma skin cancer diagnosis is still under debate. This systematic review and meta-analysis were conducted to assess the diagnostic accuracy of RCM in primary BCC. PubMed, Google Scholar, Scopus, and Web of Science databases were searched up to July 05, 2019, to collect articles concerning primary BCC diagnosis through RCM. The studies' methodological quality was assessed by the QUADAS-2 tool. The meta-analysis was conducted using Stata 13.0, RevMan 5.0, and MetaDisc 1.4 software. We included 15 studies totaling a number of 4163 lesions. The pooled sensitivity and specificity were 0.92 (95{\%} CI, 0.87–0.95; I2= 85.27{\%}) and 0.93 (95{\%} CI, 0.85–0.97; I2= 94.61{\%}), the pooled positive and negative likelihood ratios were 13.51 (95{\%} CI, 5.8–31.37; I2= 91.01{\%}) and 0.08 (95{\%} CI, 0.05–0.14; I2= 84.83{\%}), and the pooled diagnostic odds ratio was 160.31 (95{\%} CI, 64.73–397.02; I2=71{\%}). Despite the heterogeneity and risk of bias, this study demonstrates that RCM, through its high sensitivity and specificity, may have a significant clinical impact on the diagnosis of primary BCC.},
author = {Lupu and Popa and Voiculescu and Caruntu and Caruntu},
doi = {10.3390/jcm8091462},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Journal of Clinical Medicine/2019{\_}A Systematic Review and Meta-Analysis of the Accuracy of in VivoReflectance Confocal Microscopy for the Diagnosis of Primary Basal.pdf:pdf},
journal = {Journal of Clinical Medicine},
number = {9},
pages = {1462},
title = {{A Systematic Review and Meta-Analysis of the Accuracy of in VivoReflectance Confocal Microscopy for the Diagnosis of Primary Basal Cell Carcinoma}},
volume = {8},
year = {2019}
}
@article{Dinnes2018,
abstract = {Background: Melanoma has one of the fastest rising incidence rates of any cancer. It accounts for a small percentage of skin cancer cases but is responsible for the majority of skin cancer deaths. Early detection and treatment is key to improving survival; however, anxiety around missing early cases needs to be balanced against appropriate levels of referral and excision of benign lesions. Used in conjunction with clinical or dermoscopic suspicion of malignancy, or both, reflectance confocal microscopy (RCM) may reduce unnecessary excisions without missing melanoma cases. Objectives: To determine the diagnostic accuracy of reflectance confocal microscopy for the detection of cutaneous invasive melanoma and atypical intraepidermal melanocytic variants in adults with any lesion suspicious for melanoma and lesions that are difficult to diagnose, and to compare its accuracy with that of dermoscopy. Search methods: We undertook a comprehensive search of the following databases from inception up to August 2016: Cochrane Central Register of Controlled Trials; MEDLINE; Embase; and seven other databases. We studied reference lists and published systematic review articles. Selection criteria: Studies of any design that evaluated RCM alone, or RCM in comparison to dermoscopy, in adults with lesions suspicious for melanoma or atypical intraepidermal melanocytic variants, compared with a reference standard of either histological confirmation or clinical follow-up. Data collection and analysis: Two review authors independently extracted all data using a standardised data extraction and quality assessment form (based on QUADAS-2). We contacted authors of included studies where information related to the target condition or diagnostic threshold were missing. We estimated summary sensitivities and specificities per algorithm and threshold using the bivariate hierarchical model. To compare RCM with dermoscopy, we grouped studies by population (defined by difficulty of lesion diagnosis) and combined data using hierarchical summary receiver operating characteristic (SROC) methods. Analysis of studies allowing direct comparison between tests was undertaken. To facilitate interpretation of results, we computed values of specificity at the point on the SROC curve with 90{\%} sensitivity as this value lies within the estimates for the majority of analyses. We investigated the impact of using a purposely developed RCM algorithm and in-person test interpretation. Main results: The search identified 18 publications reporting on 19 study cohorts with 2838 lesions (including 658 with melanoma), which provided 67 datasets for RCM and seven for dermoscopy. Studies were generally at high or unclear risk of bias across almost all domains and of high or unclear concern regarding applicability of the evidence. Selective participant recruitment, lack of blinding of the reference test to the RCM result, and differential verification were particularly problematic. Studies may not be representative of populations eligible for RCM, and test interpretation was often undertaken remotely from the patient and blinded to clinical information. Meta-analysis found RCM to be more accurate than dermoscopy in studies of participants with any lesion suspicious for melanoma and in participants with lesions that were more difficult to diagnose (equivocal lesion populations). Assuming a fixed sensitivity of 90{\%} for both tests, specificities were 82{\%} for RCM and 42{\%} for dermoscopy for any lesion suspicious for melanoma (9 RCM datasets; 1452 lesions and 370 melanomas). For a hypothetical population of 1000 lesions at the median observed melanoma prevalence of 30{\%}, this equated to a reduction in unnecessary excisions with RCM of 280 compared to dermoscopy, with 30 melanomas missed by both tests. For studies in equivocal lesions, specificities of 86{\%} would be observed for RCM and 49{\%} for dermoscopy (7 RCM datasets; 1177 lesions and 180 melanomas). At the median observed melanoma prevalence of 20{\%}, this reduced unnecessary excisions by 296 with RCM compared with dermoscopy, with 20 melanomas missed by both tests. Across all populations, algorithms and thresholds assessed, the sensitivity and specificity of the Pellacani RCM score at a threshold of three or greater were estimated at 92{\%} (95{\%} confidence interval (CI) 87 to 95) for RCM and 72{\%} (95{\%} CI 62 to 81) for dermoscopy. Authors' conclusions: RCM may have a potential role in clinical practice, particularly for the assessment of lesions that are difficult to diagnose using visual inspection and dermoscopy alone, where the evidence suggests that RCM may be both more sensitive and specific in comparison to dermoscopy. Given the paucity of data to allow comparison with dermoscopy, the results presented require further confirmation in prospective studies comparing RCM with dermoscopy in a real-world setting in a representative population.},
author = {Dinnes, Jacqueline and Deeks, Jonathan J. and Saleh, Daniel and Chuchu, Naomi and Bayliss, Susan E. and Patel, Lopa and Davenport, Clare and Takwoingi, Yemisi and Godfrey, Kathie and Matin, Rubeta N. and Patalay, Rakesh and Williams, Hywel C.},
doi = {10.1002/14651858.CD013190},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Cochrane Database of Systematic Reviews/2018{\_}Reflectance confocal microscopy for diagnosing cutaneous melanoma in adults.pdf:pdf},
issn = {1469493X},
journal = {Cochrane Database of Systematic Reviews},
number = {12},
title = {{Reflectance confocal microscopy for diagnosing cutaneous melanoma in adults}},
volume = {2018},
year = {2018}
}
@article{Nehal2008a,
abstract = {Confocal microscopy is a new imaging modality for noninvasive real-time tissue imaging with high resolution and contrast comparable with conventional histology. Application of this technology to skin imaging during the last decade has been an exciting advance in dermatology, allowing a virtual widow into living skin without the need for a conventional biopsy or histologic processing of tissue. High-resolution noninvasive skin imaging with confocal microscopy has potential broad applications in the clinical and research arenas, including differentiating between benign and malignant skin lesions, tumor margin mapping, monitoring response to medical or surgical treatments, and pathophysiologic study of inflammatory processes.},
author = {Nehal, Kishwer S and Gareau, Dan and Rajadhyaksha, Milind},
doi = {10.1016/j.sder.2008.01.006},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Seminars in Cutaneous Medicine and Surgery/2008{\_}Skin Imaging With Reflectance Confocal Microscopy.pdf:pdf},
issn = {1085-5629 (Print)},
journal = {Seminars in cutaneous medicine and surgery},
keywords = {Confocal,Equipment Design,Humans,Microscopy,Skin,Skin Diseases,diagnosis,instrumentation,pathology},
language = {eng},
month = {mar},
number = {1},
pages = {37--43},
pmid = {18486023},
title = {{Skin imaging with reflectance confocal microscopy.}},
volume = {27},
year = {2008}
}
